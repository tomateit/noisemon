{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b2085eb-aed1-4f62-9426-9a9559b78511",
   "metadata": {},
   "source": [
    "# NER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06b83af-4ca6-4414-ad9b-21489a9a46ef",
   "metadata": {},
   "source": [
    "## Align recognized entity and vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adb00289-461e-4468-b9ff-508adf055b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/max/process/dist/app_noisemon\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc2c607b-ec75-4926-88ee-f5334c77ea0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/LaBSE-en-ru were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import spacy_alignments as tokenizations\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from typing import List, Tuple\n",
    "\n",
    "model_name: str = \"cointegrated/LaBSE-en-ru\"\n",
    "device=torch.device(\"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "model.to(device)\n",
    "embedding = None\n",
    "embedding_alignment = None\n",
    "d = 768  # dimension\n",
    "\n",
    "text = \"alpha omega\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "013fde36-be58-459b-84ae-bd2818d9670f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alpha omega'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "842457f1-8979-4e37-bef6-8f38410c1049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'alpha', 'omega', '[SEP]']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a538ba2-f71d-48b5-8b0e-77f893537ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = tokenizer([text], truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "wordpieces = tokenizer.batch_decode(encoded_text.input_ids[0])\n",
    "embedding_alignment, _ = tokenizations.get_alignments(list(text), wordpieces)\n",
    "embedding_alignment = embedding_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0848bf01-973b-41e9-a3e9-81ddc4fb2930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [1], [1], [1], [1], [], [2], [2], [2], [2], [2]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "830928f1-2264-442f-8ecc-c19bca80e223",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model_output = model(**{k: v.to(model.device) for k, v in encoded_text.items()})\n",
    "embeddings = model_output.last_hidden_state.cpu()\n",
    "embedding = torch.nn.functional.normalize(embeddings).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1015bbe7-38b9-47b1-ba6a-09b37500c1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3372, -0.2950, -0.4121,  ..., -0.4918,  0.3570, -0.5508],\n",
       "        [ 0.4493, -0.6439, -0.7166,  ..., -0.7144,  0.5637, -0.4535],\n",
       "        [ 0.7555, -0.6414, -0.3833,  ..., -0.0776,  0.6538, -0.4331],\n",
       "        [ 0.3372, -0.2950, -0.4121,  ..., -0.4918,  0.3570, -0.5508]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72455dc3-d80f-4c99-9579-019fd95c6524",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_spans = [(0,5),(6, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a038874-049b-4fe6-8d75-bbb5f1f7e840",
   "metadata": {},
   "outputs": [],
   "source": [
    "span_vectors = []\n",
    "for span in char_spans:\n",
    "    span_idxs = [idx for list_of_indices in embedding_alignment[span[0]: span[1]] for idx in\n",
    "                 list_of_indices]\n",
    "    span_idxs = sorted(set(span_idxs))\n",
    "    span_emb = embedding[span_idxs]\n",
    "    span_vector = torch.mean(span_emb, dim=0)\n",
    "    span_vectors.append(span_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "077330cc-374b-4224-b530-416d7accf3f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7555, -0.6414, -0.3833, -0.4567,  0.5232,  0.5964,  0.4074, -0.4846,\n",
       "          0.6579,  0.5078, -0.9210,  0.4519, -0.0432,  0.5566, -0.4285,  0.6470,\n",
       "         -0.5387,  0.4567,  0.4417, -0.7056,  0.5970, -0.4124, -0.0942,  0.6758,\n",
       "          0.3603,  0.5641,  0.1035, -0.7012,  0.3820,  0.7298, -0.5799,  0.6088,\n",
       "         -0.3808,  0.1039, -0.4678, -0.1365,  0.7950, -0.6784,  0.7519,  0.6894,\n",
       "         -0.0306, -0.4453,  0.7537,  0.7061, -0.5380, -0.5383,  0.5050, -0.0842,\n",
       "         -0.4656,  0.6808, -0.0627,  0.4195, -0.5654,  0.7240, -0.5126,  0.2934,\n",
       "         -0.0278,  0.4906,  0.5744, -0.2449, -0.6941, -0.4256,  0.3985, -0.6668,\n",
       "         -0.5320,  0.5095, -0.6283,  0.6955, -0.6437, -0.1254,  0.3835, -0.7899,\n",
       "          0.1866, -0.5962,  0.5720,  0.6170,  0.5044, -0.6206,  0.4666,  0.5792,\n",
       "          0.0244,  0.6072, -0.7168,  0.8859, -0.9768,  0.5029,  0.2117,  0.4687,\n",
       "         -0.4782, -0.4670,  0.5794, -0.5557,  0.5026,  0.4634, -0.4160, -0.8015,\n",
       "          0.3124,  0.5157,  0.5238,  0.4932, -0.2660,  0.6166, -0.5439, -0.2209,\n",
       "         -0.5683, -0.8638,  0.5958,  0.3886, -0.2507,  0.3105, -0.0071,  0.4970,\n",
       "          0.4644,  0.6129,  0.3331,  0.5420,  0.4270,  0.5830,  0.6172, -0.7338,\n",
       "         -0.7116,  0.6050, -0.4194,  0.3576,  0.5238,  0.4500,  0.6416,  0.4835,\n",
       "         -0.0349,  0.5316, -0.4642,  0.5193, -0.1728, -0.6303,  0.4816, -0.4301,\n",
       "         -0.3696, -0.5533, -0.6589,  0.1446, -0.6947,  0.5234,  0.4401,  0.4893,\n",
       "          0.4688,  0.4649, -0.5707,  0.5146, -0.4572, -0.4277, -0.5673,  0.6453,\n",
       "         -0.6065,  0.4391,  0.5594, -0.4841,  0.5264, -0.3508, -0.6026,  0.5194,\n",
       "          0.5654,  0.2726, -0.6517, -0.4161,  0.5014, -0.5052, -0.6440,  0.4433,\n",
       "         -0.3431, -0.6455, -0.0753, -0.6004,  0.4277, -0.4747, -0.5929, -0.3308,\n",
       "         -0.1137, -0.7408, -0.4029, -0.6067,  0.5419, -0.6293,  0.6865,  0.7421,\n",
       "         -0.8406,  0.5918,  0.3536, -0.3262, -0.4819,  0.2029,  0.5338, -0.5471,\n",
       "          0.3349, -0.7141,  0.5256,  0.2064,  0.9366,  0.6330,  0.5158, -0.5453,\n",
       "          0.0778,  0.5871, -0.6298, -0.1705,  0.8354,  0.5141, -0.1837, -0.5747,\n",
       "         -0.9556, -0.6796,  0.6159, -0.3876, -0.7926,  0.4909,  0.5226,  0.6639,\n",
       "         -0.6177, -0.5346,  0.3004,  0.6249,  0.5999, -0.5481,  0.5044,  0.5806,\n",
       "         -0.4565, -0.3365,  0.4783, -0.6199, -0.3134, -0.5718,  0.4542,  0.4516,\n",
       "          0.5196,  0.6253,  0.5962, -0.2477,  0.6824,  0.5286,  0.6157,  0.5999,\n",
       "         -0.5328,  0.5364,  0.6002, -0.4491, -0.6034,  0.6230,  0.5950,  0.5445,\n",
       "          0.5421,  0.3980, -0.7051,  0.5010,  0.9264,  0.3769, -0.2680, -0.2604,\n",
       "          0.6432,  0.6587,  0.4914,  0.1222, -0.6274,  0.3311,  0.3691,  0.6378,\n",
       "         -0.5730,  0.4631, -0.3080, -0.7278,  0.4325,  0.5717, -0.5056,  0.7192,\n",
       "          0.5220,  0.5459, -0.6734,  0.2473, -0.5007,  0.5579,  0.5332,  0.5979,\n",
       "          0.4258,  0.5992, -0.5744,  0.4845,  0.3232, -0.7112,  0.4215,  0.4566,\n",
       "          0.5364,  0.4896, -0.3489,  0.5387,  0.6435,  0.3379, -0.0822, -0.5257,\n",
       "         -0.6137, -0.6102, -0.3250, -0.5315,  0.6178, -0.5590,  0.4665,  0.0780,\n",
       "         -0.6382,  0.5269, -0.6495,  0.5476,  0.3487, -0.2423, -0.3722,  0.4111,\n",
       "         -0.5576,  0.5329,  0.4582, -0.6240, -0.2343, -0.7233,  0.4903, -0.5777,\n",
       "         -0.6390,  0.5631,  0.4979, -0.8754, -0.5319, -0.3912,  0.3890, -0.5449,\n",
       "         -0.0090, -0.6547,  0.6049,  0.5287,  0.0916,  0.3131,  0.5863, -0.1749,\n",
       "          0.5326, -0.6729,  0.5820, -0.4717,  0.2479,  0.1182,  0.4350,  0.4809,\n",
       "         -0.5201, -0.4332, -0.5573,  0.6932,  0.4703,  0.6080, -0.6083,  0.4213,\n",
       "         -0.1983, -0.5766,  0.6042,  0.5243,  0.5930,  0.5650,  0.6749,  0.8089,\n",
       "         -0.5972, -0.6536,  0.1198,  0.5926,  0.0872,  0.4820, -0.3786,  0.4616,\n",
       "         -0.5660, -0.6373, -0.6775,  0.0924, -0.0850,  0.7460,  0.5338,  0.4031,\n",
       "          0.6301,  0.3740,  0.4926, -0.2957,  0.6017, -0.6113,  0.5759,  0.7321,\n",
       "          0.4490,  0.3316, -0.7601, -0.3965,  0.6451,  0.4549,  0.4243, -0.4424,\n",
       "         -0.2552, -0.4025,  0.2437, -0.5402,  0.1982,  0.5391,  0.5503,  0.4510,\n",
       "          0.2299,  0.4375,  0.9988,  0.4095,  0.3674, -0.6001, -0.5291,  0.6721,\n",
       "          0.4564,  0.2544, -0.5795,  0.5957,  0.3954, -0.6668, -0.0486,  0.3900,\n",
       "          0.0729, -0.4566,  0.7016,  0.6545,  0.5295, -0.3375, -0.7254, -0.4483,\n",
       "         -0.5346, -0.7631, -0.4926,  0.4707, -0.5785, -0.6740,  0.6536, -0.4331,\n",
       "          0.4494,  0.4860,  0.5652, -0.3125, -0.6198,  0.5138, -0.4903, -0.6312,\n",
       "          0.4936,  0.5501,  0.5085,  0.5179, -0.6622, -0.5584,  0.5023,  0.0423,\n",
       "          0.5861,  0.5511, -0.5422, -0.7155, -0.3490,  0.5850, -0.2654,  0.5762,\n",
       "          0.5370,  0.5908,  0.5182,  0.4829, -0.7806,  0.6667,  0.6554,  0.4627,\n",
       "          0.6620, -0.4677,  0.3315,  0.5441, -0.0412, -0.7253, -0.7760, -0.1739,\n",
       "          0.5164, -0.6893,  0.5081,  0.0768, -0.9575, -0.0572,  0.7284,  0.5002,\n",
       "          0.5504,  0.6759, -0.2197, -0.5947, -0.2194,  0.5269, -0.4924,  0.6307,\n",
       "          0.5016, -0.4151,  0.8312, -0.4712, -0.5160, -0.3482, -0.0842, -0.5532,\n",
       "          0.5203, -0.5368,  0.5457, -0.5105,  0.5909, -0.4184, -0.1414,  0.6512,\n",
       "          0.5091, -0.6307,  0.4876,  0.0365, -0.5558,  0.4237,  0.5158, -0.0015,\n",
       "          0.5862, -0.9420, -0.5816, -0.4732, -0.5627,  0.5064, -0.4855, -0.5343,\n",
       "          0.5859, -0.5789,  0.7633, -0.5290, -0.4425, -0.6526, -0.5743, -0.5332,\n",
       "          0.0587,  0.3952, -0.2336, -0.6316,  0.7485,  0.4721, -0.5934, -0.5721,\n",
       "          0.5345, -0.6443,  0.3394, -0.4142,  0.5311,  0.7136,  0.5092,  0.5087,\n",
       "         -0.5403,  0.1708, -0.5556,  0.5737,  0.5536, -0.4487, -0.8745, -0.5736,\n",
       "          0.5411, -0.6584,  0.5916, -0.5660,  0.4074, -0.6015,  0.5870,  0.0421,\n",
       "         -0.4093,  0.4844,  0.4718,  0.6409,  0.3982,  0.6807,  0.5513,  0.5242,\n",
       "         -0.4198, -0.5576, -0.5422,  0.6012,  0.4537,  0.5238, -0.2700, -0.4068,\n",
       "          0.4925, -0.5141, -0.5139, -0.6890, -0.3805,  0.3493,  0.3813,  0.8858,\n",
       "          0.6208,  0.4362,  0.6504,  0.7160, -0.5740, -0.5270,  0.2615, -0.5999,\n",
       "          0.3500, -0.9126, -0.5098, -0.4341,  0.3911,  0.4658, -0.7676,  0.1369,\n",
       "          0.4411,  0.7692, -0.6820,  0.1230,  0.6527,  0.4237, -0.5751, -0.4632,\n",
       "          0.5149, -0.7037,  0.4957, -0.5637, -0.6060, -0.0831, -0.2022, -0.5576,\n",
       "          0.9176,  0.5341, -0.3028,  0.4638,  0.5539, -0.8253,  0.5279, -0.3580,\n",
       "          0.2972, -0.4617,  0.7016,  0.1357,  0.8594, -0.7714, -0.3910, -0.3200,\n",
       "          0.9750, -0.7691, -0.3688, -0.5752,  0.3612,  0.3969, -0.6678, -0.7930,\n",
       "          0.6425,  0.4694,  0.4973, -0.6897,  0.8146,  0.7708, -0.1841, -0.5410,\n",
       "          0.4249,  0.9035, -0.5179,  0.1515, -0.6181,  0.5165,  0.1771,  0.1150,\n",
       "          0.4124, -0.5574,  0.2670, -0.4438,  0.3118,  0.4319, -0.4453, -0.6689,\n",
       "         -0.8267, -0.5975,  0.6060,  0.7790,  0.1382,  0.5474, -0.5713,  0.4195,\n",
       "         -0.7070, -0.5675,  0.8773,  0.7410, -0.7536,  0.3738,  0.6222,  0.5017,\n",
       "          0.4751,  0.5660,  0.6447, -0.5447,  0.5491,  0.4766, -0.3364,  0.5125,\n",
       "         -0.3158,  0.5788, -0.1526,  0.5722, -0.3712,  0.5531, -0.7893,  0.5730,\n",
       "          0.5225, -0.5062, -0.1903, -0.5498,  0.6659,  0.5904, -0.9530,  0.5867,\n",
       "         -0.3298, -0.0687,  0.2363,  0.4595, -0.5149,  0.6458,  0.5352,  0.7977,\n",
       "          0.6629, -0.5974, -0.8240, -0.6437,  0.5322, -0.0687,  0.5073,  0.6046,\n",
       "          0.4448,  0.4057, -0.2202,  0.8021,  0.6397, -0.4130, -0.7489,  0.4680,\n",
       "         -0.3463, -0.6660, -0.5159,  0.3602,  0.0875,  0.5027,  0.3536, -0.5570,\n",
       "          0.4568,  0.0681, -0.4832,  0.6317, -0.4202, -0.4203, -0.0989, -0.5676,\n",
       "          0.5780,  0.4649,  0.5035, -0.3381,  0.3814, -0.7300, -0.5911,  0.5285,\n",
       "          0.3305, -0.0659,  0.4952, -0.3066, -0.5828,  0.4468,  0.3804,  0.3175,\n",
       "         -0.5761,  0.4211,  0.2194,  0.4767, -0.4509, -0.0776,  0.6538, -0.4331]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6f43529-4e44-4916-865a-adbddae13b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3372, -0.2950, -0.4121,  ..., -0.4918,  0.3570, -0.5508],\n",
       "        [ 0.4493, -0.6439, -0.7166,  ..., -0.7144,  0.5637, -0.4535],\n",
       "        [ 0.7555, -0.6414, -0.3833,  ..., -0.0776,  0.6538, -0.4331],\n",
       "        [ 0.3372, -0.2950, -0.4121,  ..., -0.4918,  0.3570, -0.5508]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f2607f0-f9d1-4924-82e8-7ffa607c585b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07e5690-8335-48ad-bfb6-d2dd5f2fe05b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Noisemon",
   "language": "python",
   "name": "noisemon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
