{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity recognition and embedding base building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/codeholder/code/python-playground/app_noisemon\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My baseline will be comparing embeddings of ORG chunks and company names.\n",
    "\n",
    "The large spacy model already provides embedding functionality, but those are static.\n",
    "I'm gonna need a transformer.\n",
    "For the embeddings matching I will use faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "from spacy.kb import KnowledgeBase\n",
    "from spacy.tokens import Span, DocBin, Doc\n",
    "from spacy.vocab import Vocab\n",
    "from spacy.lang.ru import Russian\n",
    "from typing import List, Callable, Iterable, Iterator, Optional, Dict, Union\n",
    "from spacy.language import Language\n",
    "from spacy.pipeline.trainable_pipe import TrainablePipe\n",
    "from spacy.pipeline.pipe import deserialize_config\n",
    "from spacy.tokens import Doc\n",
    "from spacy.vocab import Vocab\n",
    "from spacy.training import Example, validate_examples, validate_get_examples\n",
    "from spacy import util, Errors\n",
    "from spacy.util import minibatch\n",
    "from thinc.api import Model, Config, set_dropout_rate, Optimizer\n",
    "# from thinc.layers import TransformerListener\n",
    "\n",
    "from wasabi import Printer\n",
    "msg = Printer()\n",
    "\n",
    "from scripts.convert_labelstudio_to_spacy import LabelStudioToSpacyConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"ru_core_news_lg\")\n",
    "text = \"Сбербанк рассматривает возможность перехода в частную собственность, чтобы успокоить Пекин\".lower()\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "сбербанк True\n",
      "рассматривает True\n",
      "возможность True\n",
      "перехода True\n",
      "в True\n",
      "частную True\n",
      "собственность True\n",
      ", False\n",
      "чтобы True\n",
      "успокоить True\n",
      "пекин True\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.has_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "сбербанк 0 8 ORG True\n",
      "пекин 85 90 LOC True\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_, ent.has_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "100000\n",
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[1039]\n",
      " [ 774]\n",
      " [  33]\n",
      " [ 426]\n",
      " [ 258]]\n",
      "[[10957]\n",
      " [10073]\n",
      " [ 9788]\n",
      " [10911]\n",
      " [10095]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import faiss \n",
    "\n",
    "d = 300                           # dimension\n",
    "nb = 100000                      # database size\n",
    "nq = 10000                       # nb of queries\n",
    "\n",
    "xb = np.random.random((nb, d)).astype('float32')\n",
    "xb[:, 0] += np.arange(nb) / 1000.\n",
    "xq = np.random.random((nq, d)).astype('float32')\n",
    "xq[:, 0] += np.arange(nq) / 1000.\n",
    "\n",
    "                  \n",
    "index = faiss.IndexFlatL2(d)   # build the index\n",
    "print(index.is_trained)\n",
    "index.add(xb)                  # add vectors to the index\n",
    "print(index.ntotal)\n",
    "\n",
    "k = 1                          # we want to see 4 nearest neighbors\n",
    "D, I = index.search(xb[:5], k) # I - indices, D - distances\n",
    "print(I)\n",
    "print(D)\n",
    "D, I = index.search(xq, k)     # actual search\n",
    "print(I[:5])                   # neighbors of the 5 first queries\n",
    "print(I[-5:])                  # neighbors of the 5 last queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. В индексе правильные вектора\n",
    "2. Находим вектор для компании, ищем ближайший в faiss\n",
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noisemon",
   "language": "python",
   "name": "python3810_noisemon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
