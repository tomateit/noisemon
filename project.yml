title: 'Transformer-based NER pipeline for Russian'
description: "Transformer-based pipeline for NER"

assets:
  - url: "https://storage.yandexcloud.net/natasha-spacy/data/nerus-train.conllu.gz"
    dest: "assets/train.conllu.gz"
    description: "Training data"
    checksum: "9d2044ee59d09ce9be6f5719e533d481"
  - url: "https://storage.yandexcloud.net/natasha-spacy/data/nerus-dev.conllu.gz"
    dest: "assets/dev.conllu.gz"
    description: "Development data"
    checksum: "f41459ee9b781187f1456e390bf526fa"

vars:
  name: "nlp_trf"
  config: "configs/nlp_trf.cfg"
  train: "corpus/train.spacy"
  dev: "corpus/dev.spacy"
  test: "corpus/test.spacy"
  # input_path: "data/05-labeled"
  version: "2.0.0"
  # output_path: "corpus/"
  model_output: "training/${vars.name}-${vars.version}"
  trained_model: "${vars.model_output}/model-best"

# These are the directories that the project needs. The project CLI will make
# sure that they always exist.
directories: ["assets", "components", "corpus", "training", "data", "configs"]

# workflows:
#   training:
#     - corpus
#     - train
#     - evaluate


commands:
  - name: extract_conllu
    help: "Uncompress train, dev nerus corpora"
    script:
      - "gunzip --keep assets/train.conllu.gz assets/dev.conllu.gz"
    deps:
      - "assets/train.conllu.gz"
      - "assets/dev.conllu.gz"
    outputs:
      - "assets/train.conllu"
      - "assets/dev.conllu"

  # - name: "convert_labelstudio"
  #   help: "Converts labelstudio results into spacy ready-to-use docs"
  #   script:
  #     - "python ./scripts/parse_data.py --input-path=${vars.input_path} --output-folder=${vars.output_path} --most-recent  --split-dataset=3"
  #   deps:
  #     - ${vars.input_path}
  #   outputs:
  #     - ${vars.train_file}
  #     - ${vars.test_file}
  #     - ${vars.dev_file}

  - name: convert_conllu
    help: "Convert the conllu corpus data to spaCy's format"
    script:
      - "spacy convert assets/train.conllu corpus --converter conllu --n-sents 10"
      - "spacy convert assets/dev.conllu corpus --converter conllu --n-sents 10"
    deps:
      - "assets/train.conllu"
      - "assets/dev.conllu"
    outputs:
      - "corpus/train.spacy"
      - "corpus/dev.spacy"

  - name: download
    help: "Download a spaCy model with pretrained vectors and NER component"
    script:
      - "./scripts/download_spacy_model.sh"

  # - name: corpus
  #   help: "Create a training and dev set, and KB from the manually annotated data"
  #   script:
  #     - "python ./scripts/parse_data.py --input-path ${vars.input_path} --outut-folder ./corpus/ --most-recent"
  #   deps:
  #     - "${vars.input_path}"
  #   outputs_no_cache:
  #     - "corpus/${vars.train}"
  #     - "corpus/${vars.dev}"
  #     - "corpus/${vars.test}"
  #     - "corpus/${vars.kb}"


  - name: train
    help: "Train a new NER component"
    script:
      - "python -m spacy train ${vars.config} --output ${vars.model_output}  --paths.train ${vars.train} --paths.dev ${vars.dev} -c components/custom_components.py"
    deps:
      - "${vars.train}"
      - "${vars.dev}"
      - "${vars.test}"


  - name: package
    help: "Package the trained model so it can be installed"
    script:
      - "python -m spacy package training/model-best package --name core_news_trf --version 3.0.0 --force"
    deps:
      - "${vars.trained_model}"
    outputs_no_cache:
      - "package/${vars.name}-${vars.version}/dist/${vars.name}-${vars.version}.tar.gz"


  - name: evaluate
    help: "Final evaluation on the dev data and printing the results"
    script:
      - "python ./scripts/evaluate.py ./training/model-best/ assets/${vars.test}"
    deps:
      - "${vars.trained_model}"
      - "corpus/${vars.test}"

  # - name: clean
  #   help: "Remove intermediate files"
  #   script:
  #     - "rm -rf training/*"
  #     - "rm -rf corpus/*"
